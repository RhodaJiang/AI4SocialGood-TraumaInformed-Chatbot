{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "270e9010-d11a-4547-a734-b9c39e9fef9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (4.12.3)\n",
      "Collecting python-docx\n",
      "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from python-docx) (5.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /opt/conda/lib/python3.11/site-packages (from python-docx) (4.11.0)\n",
      "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: python-docx\n",
      "Successfully installed python-docx-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 python-docx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f335244f-a4b5-421c-ab95-5791a3b1b824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as 001_Centrepoint_Mitak_Story.docx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from docx import Document\n",
    "from datetime import datetime\n",
    "\n",
    "url = \"https://centrepoint.org.uk/ending-youth-homelessness/real-stories/mitaks-story-courage-face-adversity\"\n",
    "story_number = \"001\"\n",
    "org_name = \"Centrepoint\"\n",
    "person_name = \"Mitak\"\n",
    "title = f\"{story_number}_{org_name}_{person_name}_Story\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "doc = Document()\n",
    "doc.add_heading(f\"{person_name}'s Story: Courage in the Face of Adversity\", level=1)\n",
    "doc.add_paragraph(f\"Source: {url}\")\n",
    "doc.add_paragraph(f\"Retrieved on: {datetime.today().strftime('%Y-%m-%d')}\")\n",
    "doc.add_paragraph(\"\")\n",
    "\n",
    "# EXTRACTION\n",
    "all_paragraphs = soup.find_all('p')\n",
    "for p in all_paragraphs:\n",
    "    text = p.get_text(strip=True)\n",
    "    if text:\n",
    "        doc.add_paragraph(text)\n",
    "\n",
    "# SAVE\n",
    "doc.save(f\"{title}.docx\")\n",
    "print(f\"Saved as {title}.docx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38a22f58-2fca-4cac-bc17-7f42280b07b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAILED TO PROCESS https://centrepoint.org.uk/ending-youth-homelessness/real-stories/mitaks-story-courage-face-adversity: [Errno 2] No such file or directory: '/mnt/data/001_Centrepoint_Mitak_Story.docx'\n",
      "FAILED TO PROCESS https://centrepoint.org.uk/ending-youth-homelessness/real-stories/carriannes-story-centrepoint-saved-me: [Errno 2] No such file or directory: '/mnt/data/002_Centrepoint_Carrianne_Story.docx'\n",
      "FAILED TO PROCESS https://centrepoint.org.uk/ending-youth-homelessness/real-stories/kyles-story-streets-stability: [Errno 2] No such file or directory: '/mnt/data/003_Centrepoint_Kyle_Story.docx'\n",
      "FAILED TO PROCESS https://centrepoint.org.uk/ending-youth-homelessness/real-stories/dees-story-centrepoint-helpline-was-lifeline-me: [Errno 2] No such file or directory: '/mnt/data/004_Centrepoint_Dee_Story.docx'\n",
      "FAILED TO PROCESS https://centrepoint.org.uk/ending-youth-homelessness/real-stories/kylas-story-bad-times-will-pass: [Errno 2] No such file or directory: '/mnt/data/005_Centrepoint_Kyla_Story.docx'\n",
      "FAILED TO PROCESS https://centrepoint.org.uk/ending-youth-homelessness/real-stories/aysars-story-finding-acceptance-and-confidence-centrepoint: [Errno 2] No such file or directory: '/mnt/data/006_Centrepoint_Aysar_Story.docx'\n",
      "FAILED TO PROCESS https://centrepoint.org.uk/ending-youth-homelessness/real-stories/jahzyahs-story-something-good-going-happen-and-you-should-be: [Errno 2] No such file or directory: '/mnt/data/007_Centrepoint_Jahzyah_Story.docx'\n",
      "FAILED TO PROCESS https://centrepoint.org.uk/ending-youth-homelessness/real-stories/joes-story-leaving-rough-sleeping-behind: [Errno 2] No such file or directory: '/mnt/data/008_Centrepoint_Joe_Story.docx'\n",
      "FAILED TO PROCESS https://centrepoint.org.uk/ending-youth-homelessness/real-stories/laylas-story-dreaming-stable-life: [Errno 2] No such file or directory: '/mnt/data/009_Centrepoint_Layla_Story.docx'\n",
      "FAILED TO PROCESS https://centrepoint.org.uk/ending-youth-homelessness/real-stories/bens-story-lasting-relationship: [Errno 2] No such file or directory: '/mnt/data/010_Centrepoint_Ben_Story.docx'\n",
      "FAILED TO PROCESS https://centrepoint.org.uk/ending-youth-homelessness/real-stories/ziggys-story-using-my-experience-good: [Errno 2] No such file or directory: '/mnt/data/011_Centrepoint_Ziggy_Story.docx'\n",
      "FAILED TO PROCESS https://centrepoint.org.uk/ending-youth-homelessness/real-stories/bens-story-musics-always-been-thing-ive-gone: [Errno 2] No such file or directory: '/mnt/data/012_Centrepoint_Ben_Story.docx'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/data/Centrepoint_12_in_total.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 64\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# SAVE THE MERGED TEXT CONTENT AS A SINGLE TXT FILE\u001b[39;00m\n\u001b[1;32m     63\u001b[0m txt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/mnt/data/Centrepoint_12_in_total.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtxt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     65\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(combined_text)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# CONFIRM COMPLETION\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/data/Centrepoint_12_in_total.txt'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from docx import Document\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# LINKS\n",
    "urls = [\n",
    "    \"https://centrepoint.org.uk/ending-youth-homelessness/real-stories/mitaks-story-courage-face-adversity\",\n",
    "    \"https://centrepoint.org.uk/ending-youth-homelessness/real-stories/carriannes-story-centrepoint-saved-me\",\n",
    "    \"https://centrepoint.org.uk/ending-youth-homelessness/real-stories/kyles-story-streets-stability\",\n",
    "    \"https://centrepoint.org.uk/ending-youth-homelessness/real-stories/dees-story-centrepoint-helpline-was-lifeline-me\",\n",
    "    \"https://centrepoint.org.uk/ending-youth-homelessness/real-stories/kylas-story-bad-times-will-pass\",\n",
    "    \"https://centrepoint.org.uk/ending-youth-homelessness/real-stories/aysars-story-finding-acceptance-and-confidence-centrepoint\",\n",
    "    \"https://centrepoint.org.uk/ending-youth-homelessness/real-stories/jahzyahs-story-something-good-going-happen-and-you-should-be\",\n",
    "    \"https://centrepoint.org.uk/ending-youth-homelessness/real-stories/joes-story-leaving-rough-sleeping-behind\",\n",
    "    \"https://centrepoint.org.uk/ending-youth-homelessness/real-stories/laylas-story-dreaming-stable-life\",\n",
    "    \"https://centrepoint.org.uk/ending-youth-homelessness/real-stories/bens-story-lasting-relationship\",\n",
    "    \"https://centrepoint.org.uk/ending-youth-homelessness/real-stories/ziggys-story-using-my-experience-good\",\n",
    "    \"https://centrepoint.org.uk/ending-youth-homelessness/real-stories/bens-story-musics-always-been-thing-ive-gone\"\n",
    "]\n",
    "\n",
    "# DEFINE A FUNCTION TO EXTRACT NAME FROM URL SLUG\n",
    "def extract_name(url):\n",
    "    slug = url.split(\"/\")[-1]\n",
    "    first = slug.split(\"-\")[0]\n",
    "    name = first.lower().rstrip(\"'s\").rstrip(\"s\")\n",
    "    return name.capitalize()\n",
    "\n",
    "# INITIALISE A STRING TO HOLD ALL MERGED TEXT CONTENT\n",
    "combined_text = \"\"\n",
    "\n",
    "# LOOP THROUGH EACH URL TO EXTRACT AND SAVE CONTENT\n",
    "for i, url in enumerate(urls, start=1):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        article = soup.find('div', class_='article__body') or soup\n",
    "        paragraphs = article.find_all('p')\n",
    "\n",
    "        name = extract_name(url)\n",
    "        doc = Document()\n",
    "        doc.add_heading(f\"{name}'s Story\", level=1)\n",
    "        doc.add_paragraph(f\"Source: {url}\")\n",
    "        doc.add_paragraph(f\"Retrieved On: {datetime.today().strftime('%Y-%m-%d')}\")\n",
    "        doc.add_paragraph(\"\")\n",
    "\n",
    "        story_text = f\"{i:03} - {name}'s Story\\nSource: {url}\\n\\n\"\n",
    "        for p in paragraphs:\n",
    "            text = p.get_text(strip=True)\n",
    "            if text:\n",
    "                doc.add_paragraph(text)\n",
    "                story_text += text + \"\\n\"\n",
    "\n",
    "        filename = f\"/mnt/data/{i:03}_Centrepoint_{name}_Story.docx\"\n",
    "        doc.save(filename)\n",
    "        combined_text += story_text + \"\\n\" + \"=\"*80 + \"\\n\\n\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"FAILED TO PROCESS {url}: {e}\")\n",
    "\n",
    "# SAVE THE MERGED TEXT CONTENT AS A SINGLE TXT FILE\n",
    "txt_path = \"/mnt/data/Centrepoint_12_in_total.txt\"\n",
    "with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(combined_text)\n",
    "\n",
    "# CONFIRM COMPLETION\n",
    "txt_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b883eb2-8652-47f6-8d2d-376060c72333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: 001_Centrepoint_Mitak_Story.docx\n",
      "SAVED: 002_Centrepoint_Carrianne_Story.docx\n",
      "SAVED: 003_Centrepoint_Kyle_Story.docx\n",
      "SAVED: 004_Centrepoint_Dee_Story.docx\n",
      "SAVED: 005_Centrepoint_Kyla_Story.docx\n",
      "SAVED: 006_Centrepoint_Aysar_Story.docx\n",
      "SAVED: 007_Centrepoint_Jahzyah_Story.docx\n",
      "SAVED: 008_Centrepoint_Joe_Story.docx\n",
      "SAVED: 009_Centrepoint_Layla_Story.docx\n",
      "SAVED: 010_Centrepoint_Ben_Story.docx\n",
      "SAVED: 011_Centrepoint_Ziggy_Story.docx\n",
      "SAVED: 012_Centrepoint_Ben_Story.docx\n",
      "MERGED TEXT SAVED AS: Centrepoint_12_in_total.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from docx import Document\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "\n",
    "# 1. LIST OF STORY LINKS\n",
    "urls = [\n",
    "    \"https://centrepoint.org.uk/ending-youth-homelessness/real-stories/mitaks-story-courage-face-adversity\",\n",
    "    \"https://centrepoint.org.uk/ending-youth-homelessness/real-stories/carriannes-story-centrepoint-saved-me\",\n",
    "    \"https://centrepoint.org.uk/ending-youth-homelessness/real-stories/kyles-story-streets-stability\",\n",
    "    \"https://centrepoint.org.uk/ending-youth-homelessness/real-stories/dees-story-centrepoint-helpline-was-lifeline-me\",\n",
    "    \"https://centrepoint.org.uk/ending-youth-homelessness/real-stories/kylas-story-bad-times-will-pass\",\n",
    "    \"https://centrepoint.org.uk/ending-youth-homelessness/real-stories/aysars-story-finding-acceptance-and-confidence-centrepoint\",\n",
    "    \"https://centrepoint.org.uk/ending-youth-homelessness/real-stories/jahzyahs-story-something-good-going-happen-and-you-should-be\",\n",
    "    \"https://centrepoint.org.uk/ending-youth-homelessness/real-stories/joes-story-leaving-rough-sleeping-behind\",\n",
    "    \"https://centrepoint.org.uk/ending-youth-homelessness/real-stories/laylas-story-dreaming-stable-life\",\n",
    "    \"https://centrepoint.org.uk/ending-youth-homelessness/real-stories/bens-story-lasting-relationship\",\n",
    "    \"https://centrepoint.org.uk/ending-youth-homelessness/real-stories/ziggys-story-using-my-experience-good\",\n",
    "    \"https://centrepoint.org.uk/ending-youth-homelessness/real-stories/bens-story-musics-always-been-thing-ive-gone\"\n",
    "]\n",
    "\n",
    "# 2. OUTPUT FOLDER\n",
    "output_dir = \"centrepoint_stories\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 3. FUNCTION TO EXTRACT FIRST NAME FROM URL\n",
    "def extract_name(url):\n",
    "    slug = url.split(\"/\")[-1]\n",
    "    first = slug.split(\"-\")[0]\n",
    "    name = first.lower().rstrip(\"'s\").rstrip(\"s\")\n",
    "    return name.capitalize()\n",
    "\n",
    "# 4. INITIALISE MERGED TEXT\n",
    "combined_text = \"\"\n",
    "\n",
    "# 5. PROCESS EACH STORY\n",
    "for i, url in enumerate(urls, start=1):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        article = soup.find('div', class_='article__body') or soup\n",
    "        paragraphs = article.find_all('p')\n",
    "\n",
    "        name = extract_name(url)\n",
    "        doc = Document()\n",
    "        doc.add_heading(f\"{name}'s Story\", level=1)\n",
    "        doc.add_paragraph(f\"Source: {url}\")\n",
    "        doc.add_paragraph(f\"Retrieved On: {datetime.today().strftime('%Y-%m-%d')}\")\n",
    "        doc.add_paragraph(\"\")\n",
    "\n",
    "        story_text = f\"{i:03} - {name}'s Story\\nSOURCE: {url}\\n\\n\"\n",
    "\n",
    "        for p in paragraphs:\n",
    "            text = p.get_text(strip=True)\n",
    "            if text:\n",
    "                doc.add_paragraph(text)\n",
    "                story_text += text + \"\\n\"\n",
    "\n",
    "        filename = f\"{i:03}_Centrepoint_{name}_Story.docx\"\n",
    "        doc_path = os.path.join(output_dir, filename)\n",
    "        doc.save(doc_path)\n",
    "\n",
    "        combined_text += story_text + \"\\n\" + \"=\" * 80 + \"\\n\\n\"\n",
    "        print(f\"SAVED: {filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"FAILED TO PROCESS {url}: {e}\")\n",
    "\n",
    "# 6. SAVE MERGED TEXT FILE\n",
    "txt_filename = \"Centrepoint_12_in_total.txt\"\n",
    "txt_path = os.path.join(output_dir, txt_filename)\n",
    "with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(combined_text)\n",
    "\n",
    "print(f\"MERGED TEXT SAVED AS: {txt_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "084e9890-987b-4935-90fa-7b2d89d5ce2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (4.12.3)\n",
      "Requirement already satisfied: python-docx in /opt/conda/lib/python3.11/site-packages (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests) (2025.7.14)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from python-docx) (5.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /opt/conda/lib/python3.11/site-packages (from python-docx) (4.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 python-docx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61832ca2-a129-4ef4-b384-7662c980e60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed! Saved 41 stories.\n",
      "📄 Combined file: StepByStep_All_Stories.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from docx import Document\n",
    "from datetime import datetime\n",
    "\n",
    "# Your full list of StepByStep story URLs\n",
    "urls = [\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/tareks-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/sallys-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/callums-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/bradleys-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/jennys-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/lukes-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/sophies-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/hassans-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/rachels-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/nicks-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/skyes-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/dylans-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/charlies-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/kaitlins-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/laceys-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/lenas-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/wills-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/braydens-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/shannons-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/zorans-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/amys-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/joshs-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/laylas-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/maddis-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/londons-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/kalebs-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/harrys-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/chloes-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/mikes-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/carolines-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/alishas-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/daniels-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/james-sbs-trustee/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/faheems-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/taras-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/lucas-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/doras-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/jacks-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/sams-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/hollys-story/\",\n",
    "    \"https://www.stepbystep.org.uk/about-us/young-peoples-stories/mias-story/\"\n",
    "]\n",
    "\n",
    "def extract_name(url):\n",
    "    slug = url.rstrip(\"/\").split(\"/\")[-1]\n",
    "    name_part = slug.split(\"-\")[0]\n",
    "    name = name_part.lower().rstrip(\"'s\").rstrip(\"s\")\n",
    "    return name.capitalize()\n",
    "\n",
    "combined_text = \"\"\n",
    "\n",
    "for i, url in enumerate(urls, start=1):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        article = soup.find('div', class_='component rich-text') or soup\n",
    "        paragraphs = article.find_all('p')\n",
    "\n",
    "        name = extract_name(url)\n",
    "        doc = Document()\n",
    "        doc.add_heading(f\"{name}'s Story\", level=1)\n",
    "        doc.add_paragraph(f\"Source: {url}\")\n",
    "        doc.add_paragraph(f\"Retrieved On: {datetime.today().strftime('%Y-%m-%d')}\")\n",
    "        doc.add_paragraph(\"\")\n",
    "\n",
    "        story_text = f\"{i:03} - {name}'s Story\\nSource: {url}\\n\\n\"\n",
    "        for p in paragraphs:\n",
    "            text = p.get_text(strip=True)\n",
    "            if text:\n",
    "                doc.add_paragraph(text)\n",
    "                story_text += text + \"\\n\"\n",
    "\n",
    "        filename = f\"{i:03}_StepByStep_{name}_Story.docx\"\n",
    "        doc.save(filename)\n",
    "        combined_text += story_text + \"\\n\" + \"=\"*80 + \"\\n\\n\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"FAILED TO PROCESS {url}: {e}\")\n",
    "\n",
    "txt_path = \"StepByStep_All_Stories.txt\"\n",
    "with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(combined_text)\n",
    "\n",
    "print(f\"✅ Completed! Saved {len(urls)} stories.\")\n",
    "print(f\"📄 Combined file: {txt_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1483366-3e13-4687-9f7d-46b905ed8766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "output_folder = \"stepbystep_stories\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Then when saving each docx file, update the path:\n",
    "filename = os.path.join(output_folder, f\"{i:03}_StepByStep_{name}_Story.docx\")\n",
    "doc.save(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc06079d-f6dc-49f1-bba1-886d54b11430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (4.12.3)\n",
      "Requirement already satisfied: python-docx in /opt/conda/lib/python3.11/site-packages (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests) (2025.7.14)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from python-docx) (5.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /opt/conda/lib/python3.11/site-packages (from python-docx) (4.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 python-docx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0249f89c-8d97-44bb-8e47-44ba7d2c5425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed! Saved 33 stories.\n",
      "📄 Combined file: Crisis_All_Stories.txt\n",
      "📁 DOCX files saved to: crisis_stories/\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from docx import Document\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# List of URLs\n",
    "urls = [\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/piotrs-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/abdul-and-melissa-s-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/henrys-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/stephens-story-1/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/mariannes-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/evas-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/simons-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/charlottes-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/gazs-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/cons-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/zahras-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/gails-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/fadekemis-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/john-merseyside/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/petes-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/carolines-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/mohammads-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/algimantas-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/foysols-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/davids-story-3/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/stuarts-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/michelles-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/saleehas-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/attilas-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/aarons-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/andreas-story-1/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/georges-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/kings-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/andreas-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/andrews-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/eddie-s-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/sammy-s-story/\",\n",
    "    \"https://www.crisis.org.uk/get-involved/real-life-homelessness-stories/bulletins/andrei-s-story/\",\n",
    "]\n",
    "\n",
    "# Folder to save Word docs\n",
    "output_folder = \"crisis_stories\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "def extract_name(url):\n",
    "    slug = url.rstrip(\"/\").split(\"/\")[-1]\n",
    "    name = slug.split(\"-\")[0].replace(\"’\", \"\").replace(\"'\", \"\")\n",
    "    return name.capitalize()\n",
    "\n",
    "combined_text = \"\"\n",
    "\n",
    "for i, url in enumerate(urls, 1):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Locate article container (adjust based on structure)\n",
    "        content = soup.find('div', class_='page-content') or soup\n",
    "        paragraphs = content.find_all('p')\n",
    "\n",
    "        name = extract_name(url)\n",
    "        doc = Document()\n",
    "        doc.add_heading(f\"{name}'s Story\", level=1)\n",
    "        doc.add_paragraph(f\"Source: {url}\")\n",
    "        doc.add_paragraph(f\"Retrieved On: {datetime.today().strftime('%Y-%m-%d')}\")\n",
    "        doc.add_paragraph(\"\")\n",
    "\n",
    "        story_text = f\"{i:03} - {name}'s Story\\nSource: {url}\\n\\n\"\n",
    "        for p in paragraphs:\n",
    "            text = p.get_text(strip=True)\n",
    "            if text:\n",
    "                doc.add_paragraph(text)\n",
    "                story_text += text + \"\\n\"\n",
    "\n",
    "        filename = os.path.join(output_folder, f\"{i:03}_Crisis_{name}_Story.docx\")\n",
    "        doc.save(filename)\n",
    "        combined_text += story_text + \"\\n\" + \"=\" * 80 + \"\\n\\n\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ FAILED to process {url}: {e}\")\n",
    "\n",
    "# Save combined plain text\n",
    "txt_path = \"Crisis_All_Stories.txt\"\n",
    "with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(combined_text)\n",
    "\n",
    "print(f\"✅ Completed! Saved {len(urls)} stories.\")\n",
    "print(f\"📄 Combined file: {txt_path}\")\n",
    "print(f\"📁 DOCX files saved to: {output_folder}/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a233b7ba-8137-4fe1-b0c8-e15ba7f074bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (4.12.3)\n",
      "Collecting python-docx\n",
      "  Using cached python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from python-docx) (5.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /opt/conda/lib/python3.11/site-packages (from python-docx) (4.11.0)\n",
      "Using cached python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96cf6baf-e33c-4284-9d34-2c7e9c4a2049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ FAILED to process https://sheltercymru.org.uk/intention-to-action/real-stories/: 403 Client Error: Forbidden for url: https://sheltercymru.org.uk/intention-to-action/real-stories/\n",
      "⚠️ FAILED to process https://www.sash-uk.org.uk/story/jess/: 403 Client Error: Forbidden for url: https://www.sash-uk.org.uk/story/jess/\n",
      "⚠️ FAILED to process https://www.sash-uk.org.uk/story/jason/: 403 Client Error: Forbidden for url: https://www.sash-uk.org.uk/story/jason/\n",
      "⚠️ FAILED to process https://www.sash-uk.org.uk/story/heather/: 403 Client Error: Forbidden for url: https://www.sash-uk.org.uk/story/heather/\n",
      "⚠️ FAILED to process https://www.sash-uk.org.uk/story/ali-and-andrew/: 403 Client Error: Forbidden for url: https://www.sash-uk.org.uk/story/ali-and-andrew/\n",
      "✅ Completed! 25 stories saved.\n",
      "📁 DOCX files in: others_stories/\n",
      "📄 Combined stories: others_stories.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from docx import Document\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "urls = [\n",
    "    \"https://www.bpag-encompass.org.uk/stories/emilys-story/\",\n",
    "    \"https://www.bpag-encompass.org.uk/stories/tonys-story/\",\n",
    "    \"https://homelessoxfordshire.uk/2024/11/27/jamies-story-i-feel-so-proud-to-be-able-to-provide-a-home-where-my-children-can-come-and-stay/\",\n",
    "    \"https://homelessoxfordshire.uk/2025/03/26/her-way-home-ginas-story/\",\n",
    "    \"https://homelessoxfordshire.uk/2024/11/06/fayes-story-homeless-oxfordshires-impact-on-a-journey-through-homelessness/\",\n",
    "    \"https://homelessoxfordshire.uk/2024/05/02/cheryls-story-why-a-lack-of-social-and-affordable-housing-in-oxfordshire-is-contributing-to-the-housing-crisis/\",\n",
    "    \"https://homelessoxfordshire.uk/2023/10/15/jims-story/\",\n",
    "    \"https://homelessoxfordshire.uk/2023/09/15/ambers-story/\",\n",
    "    \"https://homelessoxfordshire.uk/2022/11/03/nigels-story/\",\n",
    "    \"https://homelessoxfordshire.uk/2022/02/22/eddys-story-hard-work/\",\n",
    "    \"https://homelessoxfordshire.uk/2022/01/26/emmas-story-survival/\",\n",
    "    \"https://homelessoxfordshire.uk/2021/06/25/izzys-story/\",\n",
    "    \"https://homelessoxfordshire.uk/2021/03/02/interview-with-current-client-harry/\",\n",
    "    \"https://homelessoxfordshire.uk/2020/10/19/lucys-story-part-2/\",\n",
    "    \"https://homelessoxfordshire.uk/2020/02/05/rachels-story/\",\n",
    "    \"https://homelessoxfordshire.uk/2019/11/20/lucys-story/\",\n",
    "    \"https://homelessoxfordshire.uk/2018/11/13/im-in-a-good-place-now/\",\n",
    "    \"https://homelessoxfordshire.uk/2018/10/10/life-finally-feels-good/\",\n",
    "    \"https://homelessoxfordshire.uk/2018/04/05/jons-story/\",\n",
    "    \"https://homelessoxfordshire.uk/2018/04/04/user-story-tommy/\",\n",
    "    \"https://sheltercymru.org.uk/intention-to-action/real-stories/\",\n",
    "    \"https://www.sash-uk.org.uk/story/jess/\",\n",
    "    \"https://www.sash-uk.org.uk/story/jason/\",\n",
    "    \"https://www.sash-uk.org.uk/story/heather/\",\n",
    "    \"https://www.sash-uk.org.uk/story/ali-and-andrew/\"\n",
    "]\n",
    "\n",
    "output_folder = \"others_stories\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "combined_text = \"\"\n",
    "\n",
    "for i, url in enumerate(urls, 1):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=15)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # 下面用常见的文章内容容器标签，针对几个网站做判断适配\n",
    "        # 先尝试常见class=\"content\", \"entry-content\", \"post-content\", \"page-content\"\n",
    "        content = None\n",
    "        for cls in ['content', 'entry-content', 'post-content', 'page-content']:\n",
    "            content = soup.find('div', class_=cls)\n",
    "            if content:\n",
    "                break\n",
    "        if not content:\n",
    "            content = soup.find('article') or soup.find('main') or soup.body\n",
    "\n",
    "        paragraphs = content.find_all('p') if content else []\n",
    "\n",
    "        doc = Document()\n",
    "        doc.add_heading(f\"Story {i}\", level=1)\n",
    "        doc.add_paragraph(f\"Source: {url}\")\n",
    "        doc.add_paragraph(f\"Retrieved On: {datetime.today().strftime('%Y-%m-%d')}\")\n",
    "        doc.add_paragraph(\"\")\n",
    "\n",
    "        story_text = f\"Story {i}\\nSource: {url}\\n\\n\"\n",
    "        for p in paragraphs:\n",
    "            text = p.get_text(strip=True)\n",
    "            if text:\n",
    "                doc.add_paragraph(text)\n",
    "                story_text += text + \"\\n\"\n",
    "\n",
    "        filename = os.path.join(output_folder, f\"{i:03}.docx\")\n",
    "        doc.save(filename)\n",
    "        combined_text += story_text + \"\\n\" + \"=\" * 80 + \"\\n\\n\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ FAILED to process {url}: {e}\")\n",
    "\n",
    "with open(\"others_stories.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(combined_text)\n",
    "\n",
    "print(f\"✅ Completed! {len(urls)} stories saved.\")\n",
    "print(f\"📁 DOCX files in: {output_folder}/\")\n",
    "print(f\"📄 Combined stories: others_stories.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb3f28f-8f4f-4ae5-bdf1-72a5a4a0cfac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
