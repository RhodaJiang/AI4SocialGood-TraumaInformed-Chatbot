# AI4SocialGood-TraumaInformed-Chatbot
A behavioural-science-informed, trauma-aware decision-support chatbot for UK homelessness services. It helps frontline workers identify potential trauma risks and provides ethically responsible guidance, supporting staff onboarding, skills development, and fostering a trauma-informed organisational culture.


Overview
This project develops a behavioural-science-informed, trauma-aware decision-support chatbot for UK homelessness services.
The model enables frontline workers to:

Identify potential trauma risks in real-world scenarios.

Receive guidance on responding in a trauma-informed and ethically responsible way.

The tool is designed to support:

Onboarding of new staff.

Upskilling of unqualified personnel.

Fostering individual practice improvement and wider organisational culture change.

Background
Although societal attention to marginalised populations has increased, trauma-informed practice remains inconsistent in homelessness services. This project aims to bridge that gap through a transparent, ethically grounded AI system aligned with professional social work values.

Data Source: 100 publicly available case examples from UK homelessness service organisations.

Structure: Each case includes multiple scenarios.

Process: Dataset development is fully documented in this repository.

Ethics: All data is publicly available; identifying details have been removed or anonymised.

Methodology
Model type: Domain-specific Large Language Model (LLM) / chatbot.

Approach: Combination of expert human responses (from trained social workers) and AI-generated responses.

Alignment: Reinforcement Learning with Human Feedback (RLHF) to embed professional social work values and trauma-informed principles.

Goals
Provide practical, evidence-informed decision support for frontline workers.

Embed trauma-informed and ethical practice in AI tools for social care.

Contribute to the “AI for Social Good” movement.
